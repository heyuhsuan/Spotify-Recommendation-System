{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:20.715330Z",
     "iopub.status.busy": "2021-12-17T05:44:20.714397Z",
     "iopub.status.idle": "2021-12-17T05:44:21.808185Z",
     "shell.execute_reply": "2021-12-17T05:44:21.807394Z",
     "shell.execute_reply.started": "2021-12-17T05:44:20.715276Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:21.810083Z",
     "iopub.status.busy": "2021-12-17T05:44:21.809689Z",
     "iopub.status.idle": "2021-12-17T05:44:22.522129Z",
     "shell.execute_reply": "2021-12-17T05:44:22.521334Z",
     "shell.execute_reply.started": "2021-12-17T05:44:21.810053Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/AWS_data.csv\")\n",
    "orig = pd.read_csv(\"data/data.csv\")\n",
    "genre_data = pd.read_csv('data/data_by_genres.csv')\n",
    "year_data = pd.read_csv('data/data_by_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189340, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170653, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig.drop(columns='release_date', inplace=True)  # Drop 'release_date' from orig\n",
    "orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find IDs in 'orig' that are not in 'data'\n",
    "ids_not_in_data = ~orig['id'].isin(data['id'])\n",
    "\n",
    "# Step 2: Filter rows in 'orig' where ID is not in 'data'\n",
    "rows_to_append = orig[ids_not_in_data]\n",
    "\n",
    "# Step 3: Append these rows to 'data'\n",
    "data = pd.concat([data, rows_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332594, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'id', 'duration_ms', 'year', 'artists', 'explicit', 'name',\n",
       "       'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clustering Genres with K-Means**\n",
    "\n",
    "Here, the simple K-means clustering algorithm is used to divide the genres in this dataset into ten clusters based on the numerical audio features of each genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:26.212698Z",
     "iopub.status.busy": "2021-12-17T05:44:26.212124Z",
     "iopub.status.idle": "2021-12-17T05:44:26.518808Z",
     "shell.execute_reply": "2021-12-17T05:44:26.517759Z",
     "shell.execute_reply.started": "2021-12-17T05:44:26.212632Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10))])\n",
    "X = genre_data.select_dtypes(np.number)\n",
    "cluster_pipeline.fit(X)\n",
    "genre_data['cluster'] = cluster_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clustering Songs with K-Means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-17T05:44:43.191246Z",
     "iopub.status.busy": "2021-12-17T05:44:43.190695Z",
     "iopub.status.idle": "2021-12-17T05:44:55.203359Z",
     "shell.execute_reply": "2021-12-17T05:44:55.202178Z",
     "shell.execute_reply.started": "2021-12-17T05:44:43.191203Z"
    }
   },
   "outputs": [],
   "source": [
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                                  ('kmeans', KMeans(n_clusters=20, \n",
    "                                   verbose=False))\n",
    "                                 ], verbose=False)\n",
    "\n",
    "X = data.select_dtypes(np.number)\n",
    "number_cols = list(X.columns)\n",
    "song_cluster_pipeline.fit(X)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(X)\n",
    "data['cluster_label'] = song_cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Build Recommender System**\n",
    "\n",
    "* Based on the analysis and visualizations, it’s clear that similar genres tend to have data points that are located close to each other while similar types of songs are also clustered together.\n",
    "* This observation makes perfect sense. Similar genres will sound similar and will come from similar time periods while the same can be said for songs within those genres. We can use this idea to build a recommendation system by taking the data points of the songs a user has listened to and recommending songs corresponding to nearby data points.\n",
    "* [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) is a Python client for the Spotify Web API that makes it easy for developers to fetch data and query Spotify’s catalog for songs. You have to install using `pip install spotipy`\n",
    "* After installing Spotipy, you will need to create an app on the [Spotify Developer’s page](https://developer.spotify.com/) and save your Client ID and secret key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"dca629dcc8b9492eb6f77404760b5728\",\n",
    "                                                           client_secret=\"356a267954824137922055ae5ca81dc4\"))\n",
    "\n",
    "def find_song(name, year):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['year'] = [year]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "number_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    " 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n",
    "\n",
    "def get_song_data(song, spotify_data):\n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) & (spotify_data['year'] == song['year'])].iloc[0]\n",
    "        return song_data\n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['year'])\n",
    "\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    song_vectors = []\n",
    "\n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print(f'Warning: {song[\"name\"]} does not exist in Spotify or in database')\n",
    "            continue\n",
    "        try:\n",
    "            song_vector = np.array([float(song_data[col]) for col in number_cols if col in song_data and song_data[col] is not None])\n",
    "            if song_vector.size == len(number_cols):  # Ensure vector is complete\n",
    "                song_vectors.append(song_vector)\n",
    "            else:\n",
    "                print(f'Warning: Incomplete data for {song[\"name\"]}')\n",
    "        except Exception as e:\n",
    "            print(f'Error processing song {song[\"name\"]}: {str(e)}')\n",
    "            continue\n",
    "\n",
    "    if not song_vectors:\n",
    "        return None  # Handle case where no valid songs are found\n",
    "\n",
    "    song_matrix = np.array(song_vectors)\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "def flatten_dict_list(dict_list):\n",
    "    \n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "\n",
    "def recommend_songs(song_list, spotify_data, n_songs=5):\n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "\n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    if song_center is None:\n",
    "        print('No valid song data available for recommendations.')\n",
    "        return []\n",
    "\n",
    "    scaler = song_cluster_pipeline.named_steps['scaler']\n",
    "    feature_order = scaler.feature_names_in_ if hasattr(scaler, 'feature_names_in_') else number_cols\n",
    "\n",
    "    if song_center.shape[0] != len(feature_order):\n",
    "        print(f\"Error: Expected {len(feature_order)} features, got {song_center.shape[0]}\")\n",
    "        return []\n",
    "\n",
    "    scaled_data = scaler.transform(spotify_data[feature_order])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs * 10][0])\n",
    "\n",
    "    recommended_songs = spotify_data.iloc[index]\n",
    "    recommended_songs = recommended_songs[~recommended_songs.apply(lambda x: any(\n",
    "        (x['name'] == song['name'] and x['year'] == song['year'] and x['artists'] == song['artists']) for song in song_list), axis=1)]\n",
    "\n",
    "    # Convert 'year' from float to int\n",
    "    recommendations = recommended_songs[metadata_cols].head(n_songs).to_dict(orient='records')\n",
    "    for song in recommendations:\n",
    "        song['year'] = int(song['year'])  # Convert year to integer\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Forget About Us', 'year': 2001, 'artists': 'Tim McGraw'},\n",
       " {'name': 'Moving Target', 'year': 1986, 'artists': \"['The Outfield']\"},\n",
       " {'name': 'The Only Child', 'year': 1977, 'artists': \"['Jackson Browne']\"},\n",
       " {'name': 'The Dream Is Still Alive',\n",
       "  'year': 1990,\n",
       "  'artists': \"['Wilson Phillips']\"},\n",
       " {'name': 'Polynesian People', 'year': 2000, 'artists': 'Norm'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_songs = recommend_songs([{'name': 'Come As You Are', 'year':1991},\n",
    "                {'name': 'No Excuses', 'year': 1994},\n",
    "                {'name': 'Lithium', 'year': 1992},\n",
    "                {'name': 'Where Do Broken Hearts Go','year': 2014},\n",
    "               ],  data)\n",
    "print(recommended_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(recommended_songs)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "df.to_csv('recommended_songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp recommended_songs.csv s3://badmfinal/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
